{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datasets import flowers\n",
    "from nets import resnet_v1\n",
    "from nets import resnet_utils\n",
    "from preprocessing import vgg_preprocessing\n",
    "from keras import utils\n",
    "\n",
    "from keras.applications.vgg16 import (\n",
    "    VGG16, preprocess_input, decode_predictions)\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomDataGen():\n",
    "\n",
    "    def __init__(self, dim_x, dim_y, dim_z, num_class, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.dim_z = dim_z\n",
    "        self.num_class = num_class\n",
    "        # self.augmentation = image.ImageDataGenerator(\n",
    "        #     rotation_range=20,\n",
    "        #     shear_range=0.5\n",
    "        # )\n",
    "\n",
    "    def randomize_ind(self,data):\n",
    "        indexes = np.arange(len(data))\n",
    "        np.random.shuffle(indexes)\n",
    "        return indexes\n",
    "\n",
    "    def get_data(self,list):\n",
    "\n",
    "        X = np.empty((self.batch_size, self.dim_x, self.dim_y, self.dim_z))\n",
    "        y = np.empty((self.batch_size,self.num_class))\n",
    "\n",
    "        for id, data in enumerate(list):\n",
    "            im_path = data.split(' ')[0]\n",
    "            label = int(data.split(' ')[1])\n",
    "            img = image.load_img(im_path, target_size=(self.dim_x, self.dim_y))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)[0]\n",
    "            X[id,:,:,:] = x\n",
    "\n",
    "            y_ = utils.to_categorical(label, self.num_class)\n",
    "            y[id,...] = y_\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def generate_batch(self, data):\n",
    "\n",
    "        while 1:\n",
    "            indexes = self.randomize_ind(data)\n",
    "\n",
    "            num_batch = int(len(indexes)/self.batch_size)\n",
    "            for batch_id in range(num_batch):\n",
    "                temp_list = [data[k] for k in indexes[batch_id*self.batch_size:(batch_id+1)*self.batch_size]]\n",
    "\n",
    "                X,y = self.get_data(temp_list)\n",
    "                # return self.augmentation.flow(X,y,self.batch_size)\n",
    "                yield X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_list_from_file(file_path):\n",
    "\n",
    "    data = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "num_classes = 27\n",
    "batch_size = 30\n",
    "train_data = read_img_list_from_file('/Users/vidit/Thesis/Grocery_products/train_resnet/train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-79-58e1b674f9ba>:40: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From /Users/vidit/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /Users/vidit/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:151: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From <ipython-input-79-58e1b674f9ba>:41: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From /Users/vidit/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From /Users/vidit/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "WARNING:tensorflow:From /Users/vidit/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from /Users/vidit/Thesis/Grocery_products/train_resnet/resnet_v1_101.ckpt\n",
      "run\n",
      "Finished training. Last batch loss 3.825681\n"
     ]
    }
   ],
   "source": [
    "training_generator = CustomDataGen(224, 224, 3, num_classes, batch_size).generate_batch(train_data)\n",
    "image_size = resnet_v1.resnet_v1_101.default_image_size\n",
    "\n",
    "train_dir = '/Users/vidit/Thesis/Grocery_products/train_resnet/'\n",
    "def get_init_fn():\n",
    "    \"\"\"Returns a function run by the chief worker to warm-start the training.\"\"\"\n",
    "    checkpoint_exclude_scopes=[\"resnet_v1_101/logits\"]\n",
    "    \n",
    "    exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "    variables_to_restore = []\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "\n",
    "    return slim.assign_from_checkpoint_fn(\n",
    "      os.path.join(train_dir, 'resnet_v1_101.ckpt'),\n",
    "      variables_to_restore)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    \n",
    "    \n",
    "    images = tf.placeholder(tf.float32, shape=(batch_size, 224, 224, 3))\n",
    "    labels = tf.placeholder(tf.float32, shape=(batch_size, 27))\n",
    "    \n",
    "    # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "        logits, _ = resnet_v1.resnet_v1_101(images, num_classes=num_classes, is_training=True)\n",
    "\n",
    "    # Specify the loss function:\n",
    "    slim.losses.softmax_cross_entropy(logits, labels)\n",
    "    total_loss = slim.losses.get_total_loss()\n",
    "\n",
    "    # Create some summaries to visualize the training process:\n",
    "    tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "\n",
    "    # Specify the optimizer and create the train op:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "    init_fn = get_init_fn();\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        init_fn(sess)\n",
    "        for b_images,b_labels in training_generator:\n",
    "            print('run')\n",
    "            feed_dict = {images:b_images,labels:b_labels}\n",
    "            final_loss,_ = sess.run([total_loss,train_op],feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "            print('Finished training. Last batch loss %f' % final_loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
